{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a8e124",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Random Search with Memory\n",
    "\n",
    "In this project, we will explore a simple method called \"Random Search with Memory.\" This technique is a basic form of solving problems, and while it is not as advanced as machine learning, it helps us understand the concept of trying different solutions until we find one that works.\n",
    "\n",
    "### What is Random Search with Memory?\n",
    "Random search with memory involves trying random actions and remembering the results. If we find a good solution, we can keep it and try to improve it next time. This method is like trial and error, where we learn from our mistakes.\n",
    "\n",
    "### New Gym function\n",
    "\n",
    "for this project you will need to use a new gymnasium env function. This function is shown bellow and simply takes a random action (in the case of our environment it will return a random number between 0 and 3 representing the 4 directions that the agent can move in to reach the goal)\n",
    "\n",
    "``` python\n",
    "action = env.action_space.sample()\n",
    "```\n",
    "### Implementation\n",
    "\n",
    "For this assinmnet you will need to create a list to store the succesfull path, and a list to store the current path. on each random action you will store the action in the current path list. If you recieve a reward at any time then you know that you have a sucessfull path and can store that path as the succesfull path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a random search algorythm to solve Frozen Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#configurar el entorno del lago congelado\n",
    "env = gym.make('FrozenLake-v1', map_name=\"4x4\", is_slippery=False, render_mode=\"rgb_array\")\n",
    "\n",
    "episodes = 100 #n√∫mero de episodios\n",
    "rewards_per_episode = np.zeros(episodes) #recompensas por episodio\n",
    "rgb_arrays = []\n",
    "\n",
    "# step 1: create an empty array for storing the correct path\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state, info = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "\n",
    "    # step 2: create an empty array to store the current path \n",
    "\n",
    "    while(not terminated and not truncated):\n",
    "\n",
    "        if correct_path != []:\n",
    "            # step 3: take a random action\n",
    "\n",
    "        else:\n",
    "            # step 3: generate a random action and assign it to an action variable\n",
    "\n",
    "        # step 4: add the action to the current path with append()\n",
    "\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        rgb_arrays.append(env.render())\n",
    "\n",
    "    if(reward == 1):\n",
    "        # step 5: set currect path = to current path\n",
    "\n",
    "        rewards_per_episode[episode] = 1\n",
    "\n",
    "env.close()\n",
    "\n",
    "sum_rewards = np.zeros(episodes)\n",
    "for t in range(episodes):\n",
    "    sum_rewards[t] = np.sum(rewards_per_episode[max(0, t-100):(t+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Rewards over each episode\n",
    "\n",
    "run the following code block to see the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sum_rewards)\n",
    "plt.savefig('frozen_lake8x8.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch a video of the sucessfull path\n",
    "\n",
    "run the following code block to see the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.plotting import display_video\n",
    "\n",
    "video = display_video(rgb_arrays[-20:], interval=50)\n",
    "HTML(video.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
