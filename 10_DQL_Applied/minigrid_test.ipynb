{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "#10_DQL_Applied/Minigrid_with_Monsters\n",
    "\n",
    "# Agrega el directorio principal a sys.path\n",
    "module_path = os.path.abspath(os.path.join('./Minigrid_with_Monsters'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.12.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "from Minigrid_with_Monsters.minigrid.core.constants import COLOR_NAMES\n",
    "from Minigrid_with_Monsters.minigrid.core.grid import Grid\n",
    "from Minigrid_with_Monsters.minigrid.core.mission import MissionSpace\n",
    "from Minigrid_with_Monsters.minigrid.core.world_object import Goal\n",
    "from Minigrid_with_Monsters.minigrid.minigrid_env import MiniGridEnv\n",
    "from Minigrid_with_Monsters.minigrid.core.world_object import Monster\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class LockedRoomEnv(MiniGridEnv):\n",
    "    def __init__(self, size=19, max_steps: int | None = None, **kwargs):\n",
    "        self.size = size\n",
    "        self.monster = Monster()\n",
    "\n",
    "        if max_steps is None:\n",
    "            max_steps = 10 * size\n",
    "\n",
    "        mission_space = MissionSpace(mission_func=lambda: \"\")\n",
    "        \n",
    "        super().__init__(\n",
    "            mission_space=mission_space,\n",
    "            width=size,\n",
    "            height=size,\n",
    "            max_steps=max_steps,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def _gen_grid(self, width, height):\n",
    "        # Create the grid\n",
    "        self.grid = Grid(width, height)\n",
    "\n",
    "        # Generate the surrounding walls\n",
    "        self.grid.horz_wall(0, 0)\n",
    "        self.grid.horz_wall(0, height - 1)\n",
    "        self.grid.vert_wall(0, 0)\n",
    "        self.grid.vert_wall(width - 1, 0)\n",
    "\n",
    "        room_w = width // 2\n",
    "        room_h = height // 2\n",
    "\n",
    "        # For each row of rooms\n",
    "        for j in range(0, 2):\n",
    "            # For each column\n",
    "            for i in range(0, 2):\n",
    "                xL = i * room_w\n",
    "                yT = j * room_h\n",
    "                xR = xL + room_w\n",
    "                yB = yT + room_h\n",
    "\n",
    "                # Bottom wall and door\n",
    "                if i + 1 < 2:\n",
    "                    self.grid.vert_wall(xR, yT, room_h)\n",
    "                    pos = (xR, self._rand_int(yT + 1, yB))\n",
    "                    self.grid.set(*pos, None)\n",
    "\n",
    "                # Bottom wall and door\n",
    "                if j + 1 < 2:\n",
    "                    self.grid.horz_wall(xL, yB, room_w)\n",
    "                    pos = (self._rand_int(xL + 1, xR), yB)\n",
    "                    self.grid.set(*pos, None)\n",
    "\n",
    "        # Place the agent goal and monster\n",
    "        self.place_agent()\n",
    "        self.place_obj(Goal())\n",
    "        self.monster.position = self.place_obj(self.monster)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "\n",
    "        # Check if monster can see the agent. If so, move towards it.\n",
    "        # If the monster is in the same cell as the agent, the agent is caught.\n",
    "        if self.monster.can_see(self.grid, self.agent_pos):\n",
    "            # if the monster can see the agent, move towards it\n",
    "            self.monster.move_towards(self.grid, self.agent_pos)\n",
    "\n",
    "            if self.monster.position == self.agent_pos:\n",
    "                terminated = True\n",
    "                reward = -1\n",
    "        else:\n",
    "            # if the monster can't see the agent, move randomly\n",
    "            self.monster.patrol_forward(self.grid)\n",
    "\n",
    "        self.grid.set(*self.monster.position, self.monster)\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "# from gymnasium.utils.play import play\n",
    "# import numpy as np\n",
    "\n",
    "# env = LockedRoomEnv(render_mode=\"rgb_array\", max_steps=1000)\n",
    "\n",
    "# play(env, keys_to_action={\n",
    "#     (ord(\"a\"),): 0,\n",
    "#     (ord(\"d\"),): 1,\n",
    "#     (ord(\"w\"),): 2,\n",
    "#     (ord(\"j\"),): 3,\n",
    "#     (ord(\"k\"),): 5,\n",
    "# }, noop=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 478      |\n",
      "|    ep_rew_mean      | -0.75    |\n",
      "|    exploration_rate | 0.0927   |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 1910     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000755 |\n",
      "|    n_updates        | 452      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 546      |\n",
      "|    ep_rew_mean      | -0.75    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 4365     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000379 |\n",
      "|    n_updates        | 1066     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 502      |\n",
      "|    ep_rew_mean      | -0.75    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 910      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 6026     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000152 |\n",
      "|    n_updates        | 1481     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 455      |\n",
      "|    ep_rew_mean      | -0.724   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 7279     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000109 |\n",
      "|    n_updates        | 1794     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 490      |\n",
      "|    ep_rew_mean      | -0.679   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 883      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 9804     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000145 |\n",
      "|    n_updates        | 2425     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 538      |\n",
      "|    ep_rew_mean      | -0.649   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 888      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 12918    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.99e-05 |\n",
      "|    n_updates        | 3204     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 547      |\n",
      "|    ep_rew_mean      | -0.628   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 900      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 15329    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000484 |\n",
      "|    n_updates        | 3807     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 554      |\n",
      "|    ep_rew_mean      | -0.643   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 908      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 17725    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000726 |\n",
      "|    n_updates        | 4406     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x75fdf2047b90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage, DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Initialize the environment\n",
    "env = LockedRoomEnv(render_mode=\"rgb_array\", max_steps=1000)\n",
    "\n",
    "class FlattenObservationWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        # Assuming you only want the 'image' observation\n",
    "        img_space = self.observation_space.spaces['image']\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=img_space.low.flatten(),\n",
    "            high=img_space.high.flatten(),\n",
    "            dtype=img_space.dtype\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        # Return only the flattened 'image' array\n",
    "        return obs['image'].flatten()\n",
    "    \n",
    "# Wrap the environment\n",
    "env = FlattenObservationWrapper(env)\n",
    "\n",
    "# Check the environment to ensure compatibility with SB3\n",
    "check_env(env)\n",
    "\n",
    "model = DQN('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /workspaces/AI_Pygame_Playground/10_DQL_Applied/videos/dqn-agent-step-0-to-step-500.mp4.\n",
      "Moviepy - Writing video /workspaces/AI_Pygame_Playground/10_DQL_Applied/videos/dqn-agent-step-0-to-step-500.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /workspaces/AI_Pygame_Playground/10_DQL_Applied/videos/dqn-agent-step-0-to-step-500.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
    "\n",
    "# Define the video folder and length\n",
    "video_folder = 'videos/'\n",
    "video_length = 500\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(video_folder, exist_ok=True)\n",
    "\n",
    "# Wrap the environment with VecVideoRecorder\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecVideoRecorder(env, video_folder, record_video_trigger=lambda x: x == 0, video_length=video_length, name_prefix=\"dqn-agent\")\n",
    "\n",
    "# Reset the environment\n",
    "obs = env.reset()\n",
    "\n",
    "# Run the agent for the specified number of steps and record the video\n",
    "for _ in range(video_length):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    if dones:\n",
    "        obs = env.reset()\n",
    "\n",
    "# Close the environment and save the video\n",
    "env.close()\n",
    "\n",
    "print(\"Video recorded successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
